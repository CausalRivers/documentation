{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from tools import data_path, output_path, cache_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data origin: \n",
    "Data was privately provided by authorities. Not reproducible without original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the format requires a lot of ram ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(data_path + \"brandenburg_15.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f.read()\n",
    "content = content.split(\"]]}\")  # Splitting objects at every instance of }\\n{"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "meta_stack = []\n",
    "for c in content[:-1]:\n",
    "    meta, data = c.split('\"data\": [')\n",
    "    meta = pd.DataFrame(\n",
    "        [x.split(\":\") for x in meta[2:].replace('\"', \"\").split(\", \")[:-1]]\n",
    "    )\n",
    "    data = pd.DataFrame(\n",
    "        [x.split(\", \") for x in data[1:].replace('\"', \"\").split(\"], [\")]\n",
    "    )\n",
    "    data[0] = pd.to_datetime(data[0])\n",
    "    data = data[(data[0].dt.year > 2018) & (data[0].dt.year < 2024)].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    data.loc[data[1] == \"null\", 1] = np.nan\n",
    "    data[1] = data[1].astype(float)\n",
    "    data.columns = [\"datetime\", meta[meta[0] == \"station_no\"][1].values[0][1:] + \"_b\"]\n",
    "    stack.append(data)\n",
    "    meta_stack.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(stack, open(cache_path + \"brandenburg_data_stack.p\", \"wb\"))\n",
    "pickle.dump(meta_stack, open(cache_path + \"rivers/brandenburg_meta_stack.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload to free ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = pickle.load(open(cache_path + \"/brandenburg_data_stack.p\", \"rb\"))\n",
    "meta_stack = pickle.load(open(cache_path + \"brandenburg_meta_stack.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Q for now\n",
    "stack = [\n",
    "    stack[x]\n",
    "    for x in range(len(stack))\n",
    "    if meta_stack[x].loc[meta_stack[x][0] == \"parametertype_name\", 1].values[0] == \" Q\"\n",
    "]\n",
    "meta_stack = [\n",
    "    meta_stack[x]\n",
    "    for x in range(len(meta_stack))\n",
    "    if meta_stack[x].loc[meta_stack[x][0] == \"parametertype_name\", 1].values[0] == \" Q\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6949700_b', '5896600_b', '5934903_b']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some duplicate column names exist\n",
    "counts = {\n",
    "    y: [x.columns[1] for x in stack].count(y) for y in [x.columns[1] for x in stack]\n",
    "}\n",
    "[x for x in counts.keys() if counts[x] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something is weird here (naN). Maybe come back later. for now drop some data columns:\n",
    "drop = [102, 104, 105, 115, 117, 126, 128]\n",
    "stack = [x for n, x, in enumerate(stack) if n not in drop]\n",
    "meta_stack = [x for n, x, in enumerate(meta_stack) if n not in drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = ft.reduce(lambda left, right: pd.merge(left, right, on=\"datetime\"), stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.index = stack[\"datetime\"]\n",
    "stack.drop(columns=\"datetime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace tag from earlier mistake\n",
    "stack.columns = [x[:-2] + \"_br\" for x in stack.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.index = stack.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of random parsing\n",
    "meta_prep = []\n",
    "for x in meta_stack:\n",
    "    x.index = x[0]\n",
    "    x.drop(columns=[0], inplace=True)\n",
    "    x.columns = [int(x.loc[\"station_no\"].values[0])]\n",
    "    x.index = x.index.str.replace(\"{\", \"\")\n",
    "    meta_prep.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_prep = pd.concat(meta_prep, axis=1).T\n",
    "meta_prep = meta_prep[meta_prep.columns[:7]]\n",
    "meta_prep[\"station_no\"] = meta_prep[\"station_no\"].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_meta_br(x):\n",
    "\n",
    "    response = requests.get(\n",
    "        \"https://pegelportal.brandenburg.de/messstelle.php?fgid=5&pkz=\"\n",
    "        + x\n",
    "        + \"&thema=q_graph&language=en#loaded\"\n",
    "    )\n",
    "\n",
    "    infos = (\n",
    "        response.text.split(\"station ID:</td>\")[1]\n",
    "        .split(\"</td> \\n</tr>\\n<tr>\\n<td>status:</td>\\n<td>Aktuell\")[0]\n",
    "        .replace(\"</td>\", \"\")\n",
    "        .replace(\"<td>\", \"\")\n",
    "        .replace(\"</tr>\", \"\")\n",
    "        .replace(\"<tr>\", \"\")\n",
    "        .replace(\"<td style='text-align:left'>\", \"\")\n",
    "        .split(\"\\n\")\n",
    "    )\n",
    "\n",
    "    infos = [x for x in infos if len(x) > 0]\n",
    "    infos = [x for n, x in enumerate(infos) if (n % 2 == 0)]\n",
    "\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5873500']\n",
      "['5873500', '6945301']\n",
      "['5873500', '6945301', '5895001']\n",
      "['5873500', '6945301', '5895001', '6910302']\n",
      "['5873500', '6945301', '5895001', '6910302', '5811701']\n",
      "['5873500', '6945301', '5895001', '6910302', '5811701', '6970800']\n"
     ]
    }
   ],
   "source": [
    "meta_upgrade = []\n",
    "fail = []\n",
    "for x in meta_prep[\"station_no\"].unique():\n",
    "    try:\n",
    "        meta_upgrade.append(grab_meta_br(x))\n",
    "    except:\n",
    "        fail.append(x)\n",
    "        print(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some repairs by hand:\n",
    "meta_upgrade[17] = meta_upgrade[17][:9]\n",
    "for x in range(len(meta_upgrade)):\n",
    "    if len(meta_upgrade[x]) != 9:\n",
    "        meta_upgrade[x] = meta_upgrade[x][:4] + [\"\"] + meta_upgrade[x][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_upgrade = pd.DataFrame(meta_upgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out = meta_prep.merge(meta_upgrade, left_on=\"station_no\", right_on=0, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out = meta_out[meta_out.columns[:19]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring to joint format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tiny issues.\n",
    "meta_out.loc[20, 8] = meta_out.loc[20, 9]\n",
    "meta_out.loc[meta_out[8].isnull(), 8] = \"?\"\n",
    "meta_out.loc[20, 5] = meta_out.loc[20, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str parsing height\n",
    "meta_out[8] = meta_out[8].str.split(\" m\").str[0].str.replace(\",\", \".\")\n",
    "meta_out.loc[meta_out[8] == \"?\", 8] = np.nan\n",
    "meta_out.loc[meta_out[8] == \"\", 8] = np.nan\n",
    "meta_out[8] = meta_out[8].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out.index = meta_out[\"station_no\"]\n",
    "meta_out.index.name = \"ID\"\n",
    "meta_out = meta_out[[3, \"station_latitude\", \"station_longitude\", 5, 8]]\n",
    "meta_out.columns = [\"R\", \"X\", \"Y\", \"D\", \"H\"]\n",
    "meta_out.loc[meta_out[\"D\"].isnull(), \"D\"] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard case.\n",
    "meta_out.loc[meta_out[\"D\"].str.contains(\"oberhalb der Mündung\"), \"D\"] = (\n",
    "    meta_out.loc[meta_out[\"D\"].str.contains(\"oberhalb der Mündung\"), \"D\"]\n",
    "    .str.replace(\" km<br> oberhalb der Mündung\", \"\")\n",
    "    .str.replace(\",\", \".\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to fix the inconsistencies in the specification.\n",
    "# We encode the reverse info as negative numbers to distinguish later.\n",
    "meta_out.loc[\n",
    "    meta_out[\"D\"].str.contains(\"km<br> Kilometer an der Wasserstraße\"), \"D\"\n",
    "] = \"-\" + (\n",
    "    meta_out.loc[\n",
    "        meta_out[\"D\"].str.contains(\"km<br> Kilometer an der Wasserstraße\"), \"D\"\n",
    "    ]\n",
    "    .str.replace(\" km<br> Kilometer an der Wasserstraße\", \"\")\n",
    "    .str.replace(\",\", \".\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to fix the inconsistencies in the specification.\n",
    "# We encode the reverse info as negative numbers to distinguish later.\n",
    "meta_out.loc[\n",
    "    meta_out[\"D\"].str.contains(\"km<br> Kilometer an der Wasserstraße\"), \"D\"\n",
    "] = \"-\" + (\n",
    "    meta_out.loc[\n",
    "        meta_out[\"D\"].str.contains(\"km<br> Kilometer an der Wasserstraße\"), \"D\"\n",
    "    ]\n",
    "    .str.replace(\" km<br> Kilometer an der Wasserstraße\", \"\")\n",
    "    .str.replace(\",\", \".\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out.loc[meta_out[\"D\"] == \"55,63 km<br> unterhalb Grenze CZ / DE\", \"D\"] = \"-55.63\"\n",
    "meta_out.loc[meta_out[\"D\"] == \"664,95 km<br> unterhalb der Oppamündung\", \"D\"] = (\n",
    "    \"-664.95\"\n",
    ")\n",
    "meta_out.loc[meta_out[\"D\"] == \"554,14 km<br> unterhalb der Oppamündung\", \"D\"] = (\n",
    "    \"-554.14\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out.loc[meta_out[\"D\"] == \"keine Angabe\", \"D\"] = np.nan\n",
    "meta_out.loc[meta_out[\"D\"] == \"Unknown\", \"D\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    6\n",
       "X    0\n",
       "Y    0\n",
       "D    8\n",
       "H    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_out.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out[\"D\"] = meta_out[\"D\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand correct. This infos was previously available but is not crawlable anymore somehow. \n",
    "\n",
    "meta_out.loc[\"6945301\", \"R\"] = \"Volzine\"\n",
    "meta_out.loc[\"5895001\", \"R\"] = \"Temnitz\"\n",
    "meta_out.loc[\"6910302\", \"R\"] = \"Brieskower Kanal\"\n",
    "meta_out.loc[\"5811701\", \"R\"] = \"Lychener Gewässer\"\n",
    "meta_out.loc[\"6970800\", \"R\"] = \"Salveybach\"\n",
    "\n",
    "\n",
    "meta_out.loc[\"6945301\", \"D\"] = 0.04\n",
    "meta_out.loc[\"5895001\", \"D\"] = 2.75\n",
    "meta_out.loc[\"6910302\", \"D\"] = 3.37\t\n",
    "meta_out.loc[\"5811701\", \"D\"] = 15.85\t\n",
    "meta_out.loc[\"6970800\", \"D\"] = 7.15\t\n",
    "\n",
    "meta_out.loc[\"6945301\", \"H\"] = 1.765\t\n",
    "meta_out.loc[\"5895001\", \"H\"] = 28.65\t\n",
    "meta_out.loc[\"5811701\", \"H\"] = 61.97\t\n",
    "meta_out.loc[\"6970800\", \"H\"] = 12.523\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out[\"QD\"] = -1\n",
    "meta_out[\"QH\"] = -1\n",
    "meta_out[\"QX\"] = -1\n",
    "meta_out[\"QY\"] = -1\n",
    "meta_out[\"QR\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out.loc[~(meta_out[\"X\"].isnull()), \"QX\"] = 0\n",
    "meta_out.loc[~(meta_out[\"Y\"].isnull()), \"QY\"] = 0\n",
    "meta_out.loc[~(meta_out[\"D\"].isnull()), \"QD\"] = 0\n",
    "meta_out.loc[~(meta_out[\"R\"].isnull()), \"QR\"] = 0\n",
    "meta_out.loc[~(meta_out[\"H\"].isnull()), \"QH\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHeck if leading 0 indices are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out.to_csv(output_path + \"brandenburg_meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.to_csv(output_path + \"brandenburg_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_rivers_construction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
